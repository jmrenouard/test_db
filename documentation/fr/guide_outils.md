# ğŸ› ï¸ Guide des Outils de Performance et d'Analyse de Base de DonnÃ©es

Ce guide offre une vue d'ensemble complÃ¨te des outils disponibles dans ce dÃ©pÃ´t pour les tests de performance MariaDB, la vÃ©rification des donnÃ©es et l'analyse des requÃªtes.

## ğŸ“Š PrÃ©sentation des Outils

Le projet orchestre plusieurs outils spÃ©cialisÃ©s pour mesurer diffÃ©rents aspects de la performance et de la santÃ© de la base de donnÃ©es.

| Outil | Objectif Principal | MÃ©triques ClÃ©s MesurÃ©es |
| :--- | :--- | :--- |
| **Sysbench (LUA)** | Tests de charge & Benchmarking | QPS, TPS, Latence (moyenne, max, 95Ã¨me) |
| **SQL Analyzer** | Analyse approfondie des requÃªtes | Temps d'exÃ©cution, plan `EXPLAIN`, efficacitÃ© des index |
| **Verify Data** | IntÃ©gritÃ© des DonnÃ©es | Nombre de lignes, Checksums des tables |
| **Perf Threads Reporter** | Analyse de ScalabilitÃ© | Ã‰volution des performances de 1 Ã  64 threads |
| **Interactive Runner** | ExpÃ©rience Utilisateur | ExÃ©cution assistÃ©e avec tableaux de bord HTML en direct |

---

## ğŸï¸ MÃ©triques Sysbench : Comprendre les Chiffres

Lors de l'exÃ©cution de `make bench` ou `make perf-threads`, Sysbench fournit plusieurs mÃ©triques critiques :

### 1. DÃ©bit (Le "Speed")

- **QPS (Queries Per Second) :** Le nombre total de requÃªtes SQL exÃ©cutÃ©es par seconde. Plus c'est Ã©levÃ©, mieux c'est.
- **TPS (Transactions Per Second) :** Le nombre d'exÃ©cutions complÃ¨tes du script LUA par seconde. Dans notre cas, une transaction correspond Ã  l'exÃ©cution de tout l'ensemble de requÃªtes de `employees/req_employees.sql`.

### 2. Latence (La "RÃ©activitÃ©")

- **Latence moyenne (Avg Latency) :** Le temps moyen nÃ©cessaire pour qu'une requÃªte aboutisse.
- **95Ã¨me Centile (95th Percentile) :** 95 % des requÃªtes ont Ã©tÃ© plus rapides que cette valeur. C'est un bien meilleur indicateur de la performance "rÃ©elle" que la moyenne, car il exclut les cas idÃ©aux et se concentre sur les latences de "queue".
- **Latence Max :** La requÃªte la plus lente. Une latence max Ã©levÃ©e indique gÃ©nÃ©ralement une saturation des ressources ou une activitÃ© systÃ¨me en arriÃ¨re-plan.

### 3. EfficacitÃ©

- **Events :** Le nombre total de fois oÃ¹ le script de test a Ã©tÃ© exÃ©cutÃ©.
- **Total Time :** La durÃ©e totale du test.

---

## ğŸ“ˆ Comparaison des Threads et ScalabilitÃ©

Avec `make perf-threads`, vous pouvez mesurer comment MariaDB rÃ©agit lorsque plusieurs utilisateurs (threads) se connectent simultanÃ©ment.

### Ce qu'il faut observer

- **ScalabilitÃ© LinÃ©aire :** IdÃ©alement, 2 threads devraient donner deux fois plus de QPS qu'un seul thread.
- **Le "Genou" (Point de Saturation) :** Le point oÃ¹ l'ajout de nouveaux threads n'augmente plus les QPS, voire les diminue. Cela identifie gÃ©nÃ©ralement la limite du nombre de cÅ“urs CPU ou un goulot d'Ã©tranglement E/S.
- **Augmentation de la Latence :** Ã€ mesure que les threads augmentent, le temps d'attente augmente. Surveiller l'Ã©cart entre la latence moyenne et le 95Ã¨me centile aide Ã  identifier les conflits de verrouillage (lock contention).

---

## ğŸ” Analyse des RequÃªtes SQL

L'outil `scripts/sql_analyzer.py` (via `make analyze`) fournit un examen clinique approfondi de vos requÃªtes SQL.

### MÃ©triques & Mesures

- **Temps d'exÃ©cution individuel :** Mesure prÃ©cise du temps mis par une seule requÃªte sur le jeu de donnÃ©es rÃ©el.
- **Analyse EXPLAIN :**
  - **ALL (Full Table Scan) :** Le "tueur silencieux" de performance. La base de donnÃ©es lit chaque ligne de la table.
  - **Using temporary/filesort :** Indique que le moteur crÃ©e des tables internes sur disque ou en mÃ©moire pour trier les donnÃ©es, ce qui est trÃ¨s lent pour les grands jeux de donnÃ©es.
  - **Utilisation des Index :** Montre quels index sont rÃ©ellement utilisÃ©s (colonne `key` dans EXPLAIN).

### Suggestions Intelligentes

L'outil analyse automatiquement le schÃ©ma (`information_schema`) pour identifier les index manquants sur les colonnes utilisÃ©es dans les clauses `WHERE`, `GROUP BY`, et `ORDER BY`. Il gÃ©nÃ¨re le SQL `CREATE INDEX` exact pour corriger le problÃ¨me.

---

## ğŸ—ï¸ Architecture Technique

Le diagramme suivant illustre comment les outils interagissent avec le conteneur MariaDB :

```mermaid
graph TD
    A[Makefile / Utilisateur] -- Orchestre --> B{scripts/test_runner.sh}
    
    subgraph "VÃ©rification"
    B --> C[scripts/verify_data.sh]
    end

    subgraph "Performance"
    B --> D[sysbench + LUA]
    B --> E[scripts/perf_threads_reporter.py]
    end

    subgraph "QualitÃ© & IQ"
    B --> F[scripts/sql_analyzer.py]
    end

    C -- "RequÃªtes" --> G[(MariaDB 11.8 Docker)]
    D -- "Charges" --> G
    F -- "Explain/Schema" --> G

    F -- "Produit" --> H[reports/performance_report.html]
    E -- "Produit" --> I[reports/perf_threads/scaling_report.html]
    C -- "Logs" --> J[STDOUT / Integrity Check]
    
    style G fill:#f96,stroke:#333,stroke-width:4px
    style H fill:#bbf,stroke:#333,stroke-width:2px
    style I fill:#bbf,stroke:#333,stroke-width:2px
```

---

## ğŸ“ Note PÃ©dagogique

Cet environnement est conÃ§u pour la **Formation et l'Apprentissage**. En observant la diffÃ©rence entre une requÃªte avec index et une sans, ou en voyant comment le 95Ã¨me centile de latence explose avec l'augmentation des threads, vous acquÃ©rez une comprÃ©hension pratique des mÃ©canismes internes des bases de donnÃ©es qui dÃ©passe la simple thÃ©orie.
